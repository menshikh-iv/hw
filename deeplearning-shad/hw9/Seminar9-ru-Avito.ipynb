{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование глубокого обучения в NLP\n",
    "\n",
    "Смотрите в этой серии:\n",
    " * Простые способы работать с текстом, bag of words\n",
    " * Word embedding и... нет, это не word2vec\n",
    " * Как сделать лучше? Текстовые свёрточные сети\n",
    " * Совмещение нескольких различных источников данных\n",
    " * Решение +- реальной задачи нейронками \n",
    " \n",
    "За помощь в организации свёрточной части спасибо Ирине Гольцман"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "\n",
    "Для работы этого семинара вам потреюуется nltk v3.2\n",
    "\n",
    "__Важно, что именно v3.2, чтобы правильно работал токенизатор__\n",
    "\n",
    "Устаовить/обновиться до неё можно командой\n",
    "* `sudo pip install --upgrade nltk==3.2`\n",
    "* Если у вас старый pip, предварительно нужно сделать `sudo pip install --upgrade pip`\n",
    "\n",
    "Если у вас нет доступа к этой версии - просто убедитесь, что токены в token_counts включают русские слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Для людей со слабым ПК\n",
    " * Этот семинар можно выполнить, имея относительно скромную машину (<= 4Gb RAM) \n",
    " * Для этого существует специальный флаг \"low_RAM_mode\" - если он True, семинар работает в режиме экономии вашей памяти\n",
    " * Если у вас 8GB и больше - проблем с памятью возникнуть не должно\n",
    " * Если включить режим very_low_ram, расход мамяти будет ещё меньше, но вам может быть более трудно научить нейронку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_RAM_mode = False\n",
    "very_low_RAM = False  #если у вас меньше 3GB оперативки, включите оба флага"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Познакомимся с данными\n",
    "\n",
    "Бывший kaggle-конкурс про выявление нежелательного контента.\n",
    "\n",
    "Описание конкурса есть тут - https://www.kaggle.com/c/avito-prohibited-content\n",
    "\n",
    "\n",
    "### Скачать\n",
    "Если много RAM,\n",
    " * Из данных конкурса (вкладка Data) нужно скачать avito_train.tsv и распаковать в папку с тетрадкой\n",
    "Если мало RAM,\n",
    " * Cкачайте прореженную выборку отсюда \n",
    "     * Пожатая https://yadi.sk/d/l0p4lameqw3W8\n",
    "     * Непожатая https://yadi.sk/d/I1v7mZ6Sqw2WK\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Много разных признаков:\n",
    "* 2 вида текста - заголовок и описание\n",
    "* Много специальных фичей - цена, количество телефонов/ссылок/e-mail адресов\n",
    "* Категория и субкатегория - как ни странно, категориальные фичи\n",
    "* Аттрибуты - много категориальных признаков\n",
    "\n",
    "Нужно предсказать всего 1 бинарный признак - есть ли в рекламе нежелательный контент.\n",
    "* Под нежелательным контентом понимается криминал, прон, афера, треска и прочие любимые нами темы.\n",
    "* Да, если присмотреться к заблокированным объявлениям, можно потерять аппетит и сон на пару дней.\n",
    "* Однако профессия аналитика данных обязывает вас смотреть на данные.\n",
    " * А кто сказал, что будет легко? Data Science - опасная профессия.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not low_RAM_mode:\n",
    "    # Если у вас много оперативки\n",
    "    df = pd.read_csv(\"avito_train.tsv\",sep='\\t')\n",
    "else:\n",
    "    #Если у вас меньше 4gb оперативки\n",
    "    df = pd.read_csv(\"avito_train_1kk.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3995803, 13) 0.0688212106553\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attrs</th>\n",
       "      <th>price</th>\n",
       "      <th>is_proved</th>\n",
       "      <th>is_blocked</th>\n",
       "      <th>phones_cnt</th>\n",
       "      <th>emails_cnt</th>\n",
       "      <th>urls_cnt</th>\n",
       "      <th>close_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000010</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили с пробегом</td>\n",
       "      <td>Toyota Sera, 1991</td>\n",
       "      <td>Новая оригинальная линзованая оптика на ксенон...</td>\n",
       "      <td>{\"Год выпуска\":\"1991\", \"Тип кузова\":\"Купе\", \"П...</td>\n",
       "      <td>150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000025</td>\n",
       "      <td>Услуги</td>\n",
       "      <td>Предложения услуг</td>\n",
       "      <td>Монтаж кровли</td>\n",
       "      <td>Выполняем  монтаж кровли фальцевой ^p Тел:8@@P...</td>\n",
       "      <td>{\"Вид услуги\":\"Ремонт, строительство\"}</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000094</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>Костюм Steilmann</td>\n",
       "      <td>Юбка и топ из панбархата. Под топ  трикотажная...</td>\n",
       "      <td>{\"Вид одежды\":\"Женская одежда\", \"Предмет одежд...</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000101</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили с пробегом</td>\n",
       "      <td>Ford Focus, 2011</td>\n",
       "      <td>Автомобиль в отличном техническом состоянии, в...</td>\n",
       "      <td>{\"Марка\":\"Ford\", \"Модель\":\"Focus\", \"Год выпуск...</td>\n",
       "      <td>365000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000132</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Запчасти и аксессуары</td>\n",
       "      <td>Турбина 3.0 Bar</td>\n",
       "      <td>Продам турбину на двигатель V-6 . V-8 и мощнее...</td>\n",
       "      <td>{\"Вид товара\":\"Запчасти\", \"Тип товара\":\"Для ав...</td>\n",
       "      <td>5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     itemid     category                subcategory              title  \\\n",
       "0  10000010    Транспорт      Автомобили с пробегом  Toyota Sera, 1991   \n",
       "1  10000025       Услуги          Предложения услуг      Монтаж кровли   \n",
       "2  10000094  Личные вещи  Одежда, обувь, аксессуары   Костюм Steilmann   \n",
       "3  10000101    Транспорт      Автомобили с пробегом   Ford Focus, 2011   \n",
       "4  10000132    Транспорт      Запчасти и аксессуары    Турбина 3.0 Bar   \n",
       "\n",
       "                                         description  \\\n",
       "0  Новая оригинальная линзованая оптика на ксенон...   \n",
       "1  Выполняем  монтаж кровли фальцевой ^p Тел:8@@P...   \n",
       "2  Юбка и топ из панбархата. Под топ  трикотажная...   \n",
       "3  Автомобиль в отличном техническом состоянии, в...   \n",
       "4  Продам турбину на двигатель V-6 . V-8 и мощнее...   \n",
       "\n",
       "                                               attrs   price  is_proved  \\\n",
       "0  {\"Год выпуска\":\"1991\", \"Тип кузова\":\"Купе\", \"П...  150000        NaN   \n",
       "1             {\"Вид услуги\":\"Ремонт, строительство\"}       0        NaN   \n",
       "2  {\"Вид одежды\":\"Женская одежда\", \"Предмет одежд...    1500        NaN   \n",
       "3  {\"Марка\":\"Ford\", \"Модель\":\"Focus\", \"Год выпуск...  365000        NaN   \n",
       "4  {\"Вид товара\":\"Запчасти\", \"Тип товара\":\"Для ав...    5000        NaN   \n",
       "\n",
       "   is_blocked  phones_cnt  emails_cnt  urls_cnt  close_hours  \n",
       "0           0           0           0         0         0.03  \n",
       "1           0           1           0         0        22.38  \n",
       "2           0           0           0         0         0.41  \n",
       "3           0           0           0         0         8.87  \n",
       "4           0           0           0         0        11.82  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df.shape, df.is_blocked.mean()\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](https://kaggle2.blob.core.windows.net/competitions/kaggle/3929/media/Ad.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля заблокированных объявлений 0.0688212106553\n",
      "Всего объявлений: 3995803\n"
     ]
    }
   ],
   "source": [
    "print \"Доля заблокированных объявлений\",df.is_blocked.mean()\n",
    "print \"Всего объявлений:\",len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сбалансируем выборку\n",
    "* Выборка смещена в сторону незаблокированных объявлений\n",
    " * 4 миллиона объявлений и только 250 тысяч заблокированы.\n",
    " * Давайте просто выберем случайные 250 тысяч незаблокированных объявлений и сократим выборку до полумилиона.\n",
    " * В последствии можно испоьзовать более умные способы сбалансировать выборку\n",
    "\n",
    "\n",
    "__Если у вас слабый ПК и вы видите OutOfMemory, попробуйте уменьшить размер выборки до 100 000 примеров__\n",
    "\n",
    "__Алсо если вы не хотите ждать чтения всех данных каждый раз - сохраните уменьшенную выборку и читайте её__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля заблокированных объявлений: 0.5\n",
      "Всего объявлений: 549992\n"
     ]
    }
   ],
   "source": [
    "#downsample\n",
    "\n",
    "\n",
    "#< выдели подвыборку, в которой отрицательных примеров примерно столько же, сколько положительных>\n",
    "\n",
    "bl_df = df[df.is_blocked == 1]\n",
    "df = pd.concat([bl_df, df[df.is_blocked == 0].sample(bl_df.shape[0])]).sample(frac=1.)\n",
    "\n",
    "\n",
    "print \"Доля заблокированных объявлений:\",df.is_blocked.mean()\n",
    "print \"Всего объявлений:\",len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed\n"
     ]
    }
   ],
   "source": [
    "assert df.is_blocked.mean() < 0.51\n",
    "assert df.is_blocked.mean() > 0.49\n",
    "assert len(df) <= 560000\n",
    "\n",
    "print \"All tests passed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#прореживаем данные ещё в 2 раза, если памяти не хватает\n",
    "if very_low_RAM:\n",
    "    data = data[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Токенизируем примеры\n",
    "\n",
    "Сначала соберём словарь всех возможных слов.\n",
    "Поставим каждому слову в соответствие целое число - его id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter,defaultdict\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "#словарь для всех токенов\n",
    "token_counts = Counter()\n",
    "\n",
    "#все заголовки и описания\n",
    "all_texts = np.hstack([df.description.values, df.title.values])\n",
    "\n",
    "\n",
    "#считаем частоты слов\n",
    "for s in all_texts:\n",
    "    if type(s) is not str:\n",
    "        continue\n",
    "    s = s.decode('utf8').lower()\n",
    "    tokens = tokenizer.tokenize(s)\n",
    "    for token in tokens:\n",
    "        token_counts[token] +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вырежем редкие токены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAFkCAYAAAD7dJuCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqorhRJIkVcVwIkmSqmI4kSRJVfn//UuBGp9BmgoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f926a1f5490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#распределение частот слов - большинство слов встречаются очень редко - для нас это мусор\n",
    "_ =plt.hist(token_counts.values(),range=[0,50],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#возьмём только те токены, которые встретились хотя бы 10 раз в обучающей выборке\n",
    "#информацию о том, сколько раз встретился каждый токен, можно найти в словаре token_counts\n",
    "\n",
    "min_count = 10\n",
    "max_count = 100000\n",
    "tokens = [token for (token, cnt) in token_counts.iteritems() if cnt >= min_count and cnt < max_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {t:i+1 for i,t in enumerate(tokens)}\n",
    "null_token = \"NULL\"\n",
    "token_to_id[null_token] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего токенов: 87854\n"
     ]
    }
   ],
   "source": [
    "print \"Всего токенов:\",len(token_to_id)\n",
    "if len(token_to_id) < 30000:\n",
    "    print \"Алярм! Мало токенов. Проверьте, есть ли в token_to_id юникодные символы, если нет - обновите nltk или возьмите другой токенизатор\"\n",
    "if len(token_to_id) > 1000000:\n",
    "    print \"Алярм! Много токенов. Если вы знаете, что делаете - всё ок, если нет - возможно, вы слишком слабо обрезали токены по количеству\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заменим слова на их id\n",
    "Для каждого описания установим максимальную длину. \n",
    " * Если описание больше длины - обрежем, если меньше - дополним нулями.\n",
    " * Таким образом, у нас получится матрица размера (число объявлений)x(максимальная длина)\n",
    " * Элемент под индексами i,j - номер j-того слова i-того объявления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(strings, token_to_id, max_len=150):\n",
    "    token_matrix = []\n",
    "    for s in strings:\n",
    "        if type(s) is not str:\n",
    "            token_matrix.append([0]*max_len)\n",
    "            continue\n",
    "        s = s.decode('utf8').lower()\n",
    "        tokens = tokenizer.tokenize(s)\n",
    "        token_ids = map(lambda token: token_to_id.get(token, 0), tokens)[:max_len]\n",
    "        token_ids += [0]*(max_len - len(token_ids))\n",
    "        token_matrix.append(token_ids)\n",
    "\n",
    "    return np.array(token_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "desc_tokens = vectorize(df.description.values,token_to_id,max_len = 150)\n",
    "title_tokens = vectorize(df.title.values,token_to_id,max_len = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Пример формата данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (549992, 15)\n",
      "Toyota Cavalier, 1998 -> [64697     0 44207     0     0     0     0     0     0     0] ...\n",
      "Детралекс 500 мг N 30 таб в уп. Servier (Франция) -> [15140 51787 25706 68501 62623 13612     0 26286     0 34363] ...\n",
      "Здоровье -> [15405     0     0     0     0     0     0     0     0     0] ...\n"
     ]
    }
   ],
   "source": [
    "print \"Размер матрицы:\",title_tokens.shape\n",
    "for title, tokens in zip(df.title.values[:3],title_tokens[:3]):\n",
    "    print title,'->', tokens[:10],'...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Как вы видите, всё довольно грязно. Посмотрим, сожрёт ли это нейронка __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нетекстовые признаки\n",
    "\n",
    "Часть признаков не являются строками текста: цена, количество телефонов, категория товара.\n",
    "\n",
    "Их можно обработать отдельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Возьмём числовые признаки\n",
    "df_numerical_features = df[[\"phones_cnt\",\"emails_cnt\",\"urls_cnt\",\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Возьмём one-hot encoding категорий товара.\n",
    "#Для этого можно использовать DictVectorizer (или другой ваш любимый препроцессор)\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "categories = []\n",
    "for cat_str, subcat_str in df[[\"category\",\"subcategory\"]].values:\n",
    "    \n",
    "    cat_dict = {\"category\":cat_str,\"subcategory\":subcat_str}\n",
    "    categories.append(cat_dict)\n",
    "    \n",
    "\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "cat_one_hot = vectorizer.fit_transform(categories)\n",
    "cat_one_hot = pd.DataFrame(cat_one_hot,columns=vectorizer.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_non_text = pd.merge(\n",
    "    df_numerical_features,cat_one_hot,on = np.arange(len(cat_one_hot))\n",
    ")\n",
    "del df_non_text[\"key_0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поделим данные на обучение и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#целевая переменная - есть заблокирован ли контент\n",
    "target = df.is_blocked.values.astype('int32')\n",
    "#закодированное название\n",
    "title_tokens = title_tokens.astype('int32')\n",
    "#закодированное описание\n",
    "desc_tokens = desc_tokens.astype('int32')\n",
    "\n",
    "#все нетекстовые признаки\n",
    "df_non_text = df_non_text.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/.virtualenvs/math/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#поделим всё это на обучение и тест\n",
    "from sklearn.cross_validation import train_test_split\n",
    "data_tuple = train_test_split(title_tokens,desc_tokens,df_non_text.values,target)\n",
    "\n",
    "title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts = data_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохраним данные [опционально] \n",
    "\n",
    "* В этот момент вы можете сохранить все НУЖНЫЕ данные на диск и перезапусатить тетрадку, после чего считать их - чтобы выкинуть всё ненужное.\n",
    " * рекомендуется, если у вас мало памяти\n",
    "* Для этого нужно один раз выполнить эту клетку с save_prepared_data=True. После этого можно начинать тетрадку с ЭТОЙ табы в режиме read_prepared_data=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Читаем сохранённые данные...\n",
      "готово\n"
     ]
    }
   ],
   "source": [
    "save_prepared_data = False #сохранить\n",
    "read_prepared_data = True #cчитать\n",
    "\n",
    "#за 1 раз данные можно либо записать, либо прочитать, но не и то и другое вместе\n",
    "assert not (save_prepared_data and read_prepared_data)\n",
    "\n",
    "\n",
    "if save_prepared_data:\n",
    "    print \"Сохраняем подготовленные данные... (может занять до 3 минут)\"\n",
    "\n",
    "    import pickle\n",
    "    with open(\"preprocessed_data.pcl\",'w') as fout:\n",
    "        pickle.dump(data_tuple,fout)\n",
    "    with open(\"token_to_id.pcl\",'w') as fout:\n",
    "        pickle.dump(token_to_id,fout)\n",
    "\n",
    "    print \"готово\"\n",
    "    \n",
    "elif read_prepared_data:\n",
    "    print \"Читаем сохранённые данные...\"\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    with open(\"preprocessed_data.pcl\",'r') as fin:\n",
    "        data_tuple = pickle.load(fin)\n",
    "    title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts = data_tuple\n",
    "    with open(\"token_to_id.pcl\",'r') as fin:\n",
    "        token_to_id = pickle.load(fin)\n",
    "\n",
    "\n",
    "        \n",
    "    #повторно импортируем библиотеки, чтобы было удобно перезапускать тетрадку с этой клетки\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "\n",
    "        \n",
    "    print \"готово\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поучим нейронку\n",
    "\n",
    "Поскольку у нас есть несколько источников данных, наша нейронная сеть будет немного отличаться от тех, что вы тренировали раньше.\n",
    "\n",
    "* Отдельный вход для заголовка\n",
    " * свёртка + global max pool или RNN\n",
    "* Отдельный вход для описания\n",
    " * свёртка + global max pool или RNN\n",
    "* Отдельный вход для категориальных признаков\n",
    " * обычные полносвязные слои или какие-нибудь трюки\n",
    " \n",
    "Всё это нужно как-то смешать - например, сконкатенировать\n",
    "\n",
    "* Выход - обычный двухклассовый выход\n",
    " * 1 сигмоидальный нейрон и binary_crossentropy\n",
    " * 2 нейрона с softmax и categorical_crossentropy - то же самое, что 1 сигмоидальный\n",
    " * 1 нейрон без нелинейности (lambda x: x) и hinge loss\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Quadro M1000M (CNMeM is disabled, cuDNN 5105)\n",
      "/home/ivan/.virtualenvs/math/local/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "#загрузим библиотеки\n",
    "import lasagne\n",
    "from theano import tensor as T\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3 входа и 1 выход\n",
    "title_token_ids = T.matrix(\"title_token_ids\",dtype='int32')\n",
    "desc_token_ids = T.matrix(\"desc_token_ids\",dtype='int32')\n",
    "categories = T.matrix(\"categories\",dtype='float32')\n",
    "target_y = T.ivector(\"is_blocked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Архитектура нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_inp = lasagne.layers.InputLayer((None,title_tr.shape[1]),input_var=title_token_ids)\n",
    "descr_inp = lasagne.layers.InputLayer((None,desc_tr.shape[1]),input_var=desc_token_ids)\n",
    "cat_inp = lasagne.layers.InputLayer((None,nontext_tr.shape[1]), input_var=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Описание\n",
    "descr_nn = lasagne.layers.EmbeddingLayer(descr_inp, input_size=len(token_to_id)+1, output_size=128)\n",
    "#поменять порядок осей с [batch, time, unit] на [batch,unit,time], чтобы свёртки шли по оси времени, а не по нейронам\n",
    "descr_nn = lasagne.layers.DimshuffleLayer(descr_nn, [0,2,1])\n",
    "# 1D свёртка на ваш вкус\n",
    "descr_nn = lasagne.layers.Conv1DLayer(descr_nn, num_filters=7, filter_size=7)\n",
    "# максимум по времени для каждого нейрона\n",
    "descr_nn = lasagne.layers.GlobalPoolLayer(descr_nn,pool_function=T.max)\n",
    "\n",
    "#А ещё можно делать несколько параллельных свёрток разного размера или стандартный пайплайн \n",
    "#1dconv -> 1d max pool ->1dconv и в конце global pool \n",
    "\n",
    "\n",
    "# Заголовок\n",
    "######### title_nn = <текстовая свёрточная сеть для заголовков (title_inp)>\n",
    "\n",
    "title_nn = lasagne.layers.EmbeddingLayer(title_inp, input_size=len(token_to_id)+1, output_size=128)\n",
    "title_nn = lasagne.layers.DimshuffleLayer(title_nn, [0,2,1])\n",
    "title_nn = lasagne.layers.Conv1DLayer(title_nn, num_filters=5, filter_size=5)\n",
    "title_nn = lasagne.layers.GlobalPoolLayer(title_nn, pool_function=T.max)\n",
    "\n",
    "\n",
    "# Нетекстовые признаки\n",
    "######### cat_nn = <простая полносвязная сеть для нетекстовых признаков (cat_inp)>\n",
    "cat_nn = lasagne.layers.DenseLayer(cat_inp, 512)\n",
    "cat_nn = lasagne.layers.DenseLayer(cat_nn, 256)\n",
    "cat_nn = lasagne.layers.DenseLayer(cat_nn, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### nn = <объединение всех 3 сетей в одну (например lasagne.layers.concat) >   \n",
    "nn = lasagne.layers.concat([descr_nn, title_nn, cat_nn])\n",
    "\n",
    "nn = lasagne.layers.DenseLayer(nn, 1024)\n",
    "nn = lasagne.layers.DropoutLayer(nn, p=0.05)\n",
    "nn = lasagne.layers.DenseLayer(nn, 1, nonlinearity=lasagne.nonlinearities.linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Целевая функция и обновления весов\n",
    "\n",
    "* Делаем всё стандартно:\n",
    " * получаем предсказание\n",
    " * считаем функцию потерь\n",
    " * вычисляем обновления весов\n",
    " * компилируем итерацию обучения и оценки весов\n",
    " \n",
    " \n",
    "* Hinge loss\n",
    " * $ L_i = \\max(0, \\delta - t_i p_i) $\n",
    " * Важный параметр - delta - насколько глубоко пример должен быть в правильном классе, чтобы перестать нас волновать\n",
    " * В описании функции в документации может быть что-то про ограничения на +-1 - не верьте этому - главное, чтобы в функции по умолчанию стоял флаг `binary = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Все обучаемые параметры сети\n",
    "weights = lasagne.layers.get_all_params(nn,trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Обычное предсказание нейронки\n",
    "prediction = lasagne.layers.get_output(nn)[:,0]\n",
    "\n",
    "#функция потерь для prediction\n",
    "loss = lasagne.objectives.binary_hinge_loss(prediction, target_y, delta = 1.0, log_odds=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Шаг оптимизации весов\n",
    "updates = lasagne.updates.adam(loss, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтобы оценивать качество сети, в которой есть элемент случайности \n",
    " * Dropout, например,\n",
    " * Нужно отдельно вычислить ошибку для случая, когда dropout выключен (deterministic = True)\n",
    " * К слову, неплохо бы убедиться, что droput нам вообще нужен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Предсказание нейронки без учёта dropout и прочего шума - если он есть\n",
    "det_prediction = lasagne.layers.get_output(nn,deterministic=True)[:,0]\n",
    "\n",
    "#функция потерь для det_prediction\n",
    "det_loss = lasagne.objectives.binary_hinge_loss(prediction, target_y, delta = 1.0, log_odds=True).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скомпилируем функции обучения и оценки качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_fun = theano.function([desc_token_ids,title_token_ids,categories,target_y],\n",
    "                            [loss,prediction],\n",
    "                            updates = updates)\n",
    "eval_fun = theano.function([desc_token_ids,title_token_ids,categories,target_y],\n",
    "                           [det_loss,det_prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Главный цикл обучения\n",
    "* Всё как обычно - в цикле по минибатчам запускаем функцию обновления весов.\n",
    "* Поскольку выборка огромна, а чашки чая хватает в среднем на  100к примеров, будем на каждой эпохе пробегать только часть примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#average precision at K\n",
    "\n",
    "from oracle import APatK, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# наш старый знакомый - итератор по корзинкам - теперь умеет работать с произвольным числом каналов (название, описание, категории, таргет)\n",
    "\n",
    "def iterate_minibatches(*arrays,**kwargs):\n",
    "    \n",
    "    batchsize=kwargs.get(\"batchsize\",100)\n",
    "    shuffle = kwargs.get(\"shuffle\",True)\n",
    "    \n",
    "    if shuffle:\n",
    "        indices = np.arange(len(arrays[0]))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(arrays[0]) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield [arr[excerpt] for arr in arrays]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что можно покрутить?\n",
    "\n",
    "* batch_size - сколько примеров обрабатывается за 1 раз\n",
    "  * Чем больше, тем оптимизация стабильнее, но тем и медленнее на начальном этапе\n",
    "  * Возможно имеет смысл увеличивать этот параметр на поздних этапах обучения\n",
    "* minibatches_per_epoch - количество минибатчей, после которых эпоха принудительно завершается\n",
    "  * Не влияет на обучение - при малых значениях просто будет чаще печататься отчёт\n",
    "  * Ставить 10 или меньше имеет смысл только для того, чтобы убедиться, что ваша сеть не упала с ошибкой\n",
    "* n_epochs - сколько всего эпох сеть будет учиться\n",
    "  * Никто не отменял `n_epochs = 10**10` и остановку процесса вручную по возвращению с дачи/из похода. \n",
    "\n",
    "\n",
    "Tips:\n",
    "\n",
    "* Если вы выставили небольшой minibatches_per_epoch, качество сети может сильно скакать возле 0.5 на первых итерациях, пока сеть почти ничему не научилась.\n",
    "\n",
    "* На первых этапах попытки стоит сравнивать в первую очередь по AUC, как по самой стабильной метрике.\n",
    "\n",
    "* Метрика Average Precision at top 2.5% (APatK) - сама по себе очень нестабильная на маленьких выборках, поэтому её имеет смысл оценивать на на всех примерах (см. код ниже). Для менее, чем 10000 примеров она вовсе неинформативна.\n",
    "\n",
    "* Для сравнения методов оптимизации и регуляризаторов будет очень полезно собирать метрики качества после каждой итерации и строить график по ним после обучения\n",
    "\n",
    "* Как только вы убедились, что сеть не упала - имеет смысл дать ей покрутиться - на стандартном ноутбуке хотя бы пару часов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Val:\n",
      "\tloss: 972.978793151\n",
      "\tacc: 0.685742574257\n",
      "\tauc: 0.757086616748\n",
      "\tap@k: 0.975204405762\n",
      "Epoch: 2\n",
      "Val:\n",
      "\tloss: 983.613869256\n",
      "\tacc: 0.751138613861\n",
      "\tauc: 0.819456951412\n",
      "\tap@k: 0.99502567113\n",
      "Epoch: 3\n",
      "Val:\n",
      "\tloss: 359.09561824\n",
      "\tacc: 0.83702970297\n",
      "\tauc: 0.892186341059\n",
      "\tap@k: 0.998452680168\n",
      "Epoch: 4\n",
      "Val:\n",
      "\tloss: 8977.89359013\n",
      "\tacc: 0.55797029703\n",
      "\tauc: 0.348862219698\n",
      "\tap@k: 0.167574813359\n",
      "Epoch: 5\n",
      "Val:\n",
      "\tloss: 472.690552062\n",
      "\tacc: 0.856138613861\n",
      "\tauc: 0.892832754785\n",
      "\tap@k: 1.0\n",
      "Epoch: 6\n",
      "Val:\n",
      "\tloss: 0.877591768919\n",
      "\tacc: 0.922673267327\n",
      "\tauc: 0.971123150992\n",
      "\tap@k: 0.990525598862\n",
      "Epoch: 7\n",
      "Val:\n",
      "\tloss: 0.306207907267\n",
      "\tacc: 0.932772277228\n",
      "\tauc: 0.976202750973\n",
      "\tap@k: 0.999031321665\n",
      "Epoch: 8\n",
      "Val:\n",
      "\tloss: 0.990943672546\n",
      "\tacc: 0.90896039604\n",
      "\tauc: 0.954670334949\n",
      "\tap@k: 0.773297699795\n",
      "Epoch: 9\n",
      "Val:\n",
      "\tloss: 0.226562939575\n",
      "\tacc: 0.938613861386\n",
      "\tauc: 0.980822934434\n",
      "\tap@k: 1.0\n",
      "Epoch: 10\n",
      "Val:\n",
      "\tloss: 0.197740530812\n",
      "\tacc: 0.936831683168\n",
      "\tauc: 0.981226543184\n",
      "\tap@k: 0.999862674797\n",
      "Epoch: 11\n",
      "Val:\n",
      "\tloss: 0.196851044346\n",
      "\tacc: 0.940891089109\n",
      "\tauc: 0.983000749021\n",
      "\tap@k: 1.0\n",
      "Epoch: 12\n",
      "Val:\n",
      "\tloss: 0.177583574921\n",
      "\tacc: 0.94198019802\n",
      "\tauc: 0.983406452819\n",
      "\tap@k: 0.999764054494\n",
      "Epoch: 13\n",
      "Val:\n",
      "\tloss: 0.172031773415\n",
      "\tacc: 0.943118811881\n",
      "\tauc: 0.984092279456\n",
      "\tap@k: 0.998639252112\n",
      "Epoch: 14\n",
      "Val:\n",
      "\tloss: 0.157365242889\n",
      "\tacc: 0.945792079208\n",
      "\tauc: 0.985195895632\n",
      "\tap@k: 1.0\n",
      "Epoch: 15\n",
      "Val:\n",
      "\tloss: 0.15568504639\n",
      "\tacc: 0.949257425743\n",
      "\tauc: 0.98590934588\n",
      "\tap@k: 0.999156289634\n",
      "Epoch: 16\n",
      "Val:\n",
      "\tloss: 0.147315926883\n",
      "\tacc: 0.949603960396\n",
      "\tauc: 0.985844943241\n",
      "\tap@k: 0.998478126205\n",
      "Epoch: 17\n",
      "Val:\n",
      "\tloss: 0.138348436497\n",
      "\tacc: 0.95202970297\n",
      "\tauc: 0.987739373252\n",
      "\tap@k: 0.996484184959\n",
      "Epoch: 18\n",
      "Val:\n",
      "\tloss: 0.125553830291\n",
      "\tacc: 0.955643564356\n",
      "\tauc: 0.988915633005\n",
      "\tap@k: 1.0\n",
      "Epoch: 19\n",
      "Val:\n",
      "\tloss: 0.136757150711\n",
      "\tacc: 0.951485148515\n",
      "\tauc: 0.98684791145\n",
      "\tap@k: 0.996552338707\n",
      "Epoch: 20\n",
      "Val:\n",
      "\tloss: 0.124096631392\n",
      "\tacc: 0.954306930693\n",
      "\tauc: 0.988396856766\n",
      "\tap@k: 1.0\n",
      "Epoch: 21\n",
      "Val:\n",
      "\tloss: 0.123961904164\n",
      "\tacc: 0.956782178218\n",
      "\tauc: 0.988811705279\n",
      "\tap@k: 1.0\n",
      "Epoch: 22\n",
      "Val:\n",
      "\tloss: 3.77256372595\n",
      "\tacc: 0.874257425743\n",
      "\tauc: 0.907296003466\n",
      "\tap@k: 0.365280014318\n",
      "Epoch: 23\n",
      "Val:\n",
      "\tloss: 0.12303081988\n",
      "\tacc: 0.954851485149\n",
      "\tauc: 0.98863226866\n",
      "\tap@k: 1.0\n",
      "Epoch: 24\n",
      "Val:\n",
      "\tloss: 0.118564091746\n",
      "\tacc: 0.954158415842\n",
      "\tauc: 0.988815641546\n",
      "\tap@k: 0.999589495613\n",
      "Epoch: 25\n",
      "Val:\n",
      "\tloss: 0.117655971534\n",
      "\tacc: 0.95698019802\n",
      "\tauc: 0.989393743813\n",
      "\tap@k: 0.999706055549\n",
      "Epoch: 26\n",
      "Val:\n",
      "\tloss: 0.106164598577\n",
      "\tacc: 0.960742574257\n",
      "\tauc: 0.990597472886\n",
      "\tap@k: 1.0\n",
      "Epoch: 27\n",
      "Val:\n",
      "\tloss: 0.108385096914\n",
      "\tacc: 0.958316831683\n",
      "\tauc: 0.990746015923\n",
      "\tap@k: 0.998378484103\n",
      "Epoch: 28\n",
      "Val:\n",
      "\tloss: 0.108662462612\n",
      "\tacc: 0.958811881188\n",
      "\tauc: 0.990189255692\n",
      "\tap@k: 0.99985008696\n",
      "Epoch: 29\n",
      "Val:\n",
      "\tloss: 0.103436006568\n",
      "\tacc: 0.960792079208\n",
      "\tauc: 0.990814522276\n",
      "\tap@k: 0.994638719755\n",
      "Epoch: 30\n",
      "Val:\n",
      "\tloss: 0.109417676729\n",
      "\tacc: 0.957425742574\n",
      "\tauc: 0.989948715688\n",
      "\tap@k: 0.995630181939\n",
      "Epoch: 31\n",
      "Val:\n",
      "\tloss: 0.100314411651\n",
      "\tacc: 0.961782178218\n",
      "\tauc: 0.991267754623\n",
      "\tap@k: 0.995532325724\n",
      "Epoch: 32\n",
      "Val:\n",
      "\tloss: 0.109045053879\n",
      "\tacc: 0.957425742574\n",
      "\tauc: 0.990160457187\n",
      "\tap@k: 0.998020995126\n",
      "Epoch: 33\n",
      "Val:\n",
      "\tloss: 0.0981311778335\n",
      "\tacc: 0.961782178218\n",
      "\tauc: 0.991735703446\n",
      "\tap@k: 0.995734218266\n",
      "Epoch: 34\n",
      "Val:\n",
      "\tloss: 0.101775834744\n",
      "\tacc: 0.960742574257\n",
      "\tauc: 0.991437350039\n",
      "\tap@k: 1.0\n",
      "Epoch: 35\n",
      "Val:\n",
      "\tloss: 0.0999424616596\n",
      "\tacc: 0.961237623762\n",
      "\tauc: 0.991115179824\n",
      "\tap@k: 1.0\n",
      "Epoch: 36\n",
      "Val:\n",
      "\tloss: 0.0981180345533\n",
      "\tacc: 0.961386138614\n",
      "\tauc: 0.991468775761\n",
      "\tap@k: 0.995630181939\n",
      "Epoch: 37\n",
      "Val:\n",
      "\tloss: 0.098634475524\n",
      "\tacc: 0.961336633663\n",
      "\tauc: 0.991820964215\n",
      "\tap@k: 1.0\n",
      "Epoch: 38\n",
      "Val:\n",
      "\tloss: 0.10072062554\n",
      "\tacc: 0.960693069307\n",
      "\tauc: 0.991312973607\n",
      "\tap@k: 0.999920380616\n",
      "Epoch: 39\n",
      "Val:\n",
      "\tloss: 0.0987539230253\n",
      "\tacc: 0.96198019802\n",
      "\tauc: 0.992238180041\n",
      "\tap@k: 1.0\n",
      "Epoch: 40\n",
      "Val:\n",
      "\tloss: 0.0981343518418\n",
      "\tacc: 0.961534653465\n",
      "\tauc: 0.991644400122\n",
      "\tap@k: 1.0\n",
      "Epoch: 41\n",
      "Val:\n",
      "\tloss: 0.0932799579984\n",
      "\tacc: 0.963415841584\n",
      "\tauc: 0.992306092821\n",
      "\tap@k: 0.99855255565\n",
      "Epoch: 42\n",
      "Val:\n",
      "\tloss: 0.0920293129258\n",
      "\tacc: 0.964356435644\n",
      "\tauc: 0.992080389483\n",
      "\tap@k: 1.0\n",
      "Epoch: 43\n",
      "Val:\n",
      "\tloss: 0.0972348694108\n",
      "\tacc: 0.962722772277\n",
      "\tauc: 0.991610917422\n",
      "\tap@k: 1.0\n",
      "Epoch: 44\n",
      "Val:\n",
      "\tloss: 0.0947899517352\n",
      "\tacc: 0.964108910891\n",
      "\tauc: 0.991978200685\n",
      "\tap@k: 0.99899436176\n",
      "Epoch: 45\n",
      "Val:\n",
      "\tloss: 0.0973888825012\n",
      "\tacc: 0.963069306931\n",
      "\tauc: 0.991664956048\n",
      "\tap@k: 0.997379529676\n",
      "Epoch: 46\n",
      "Val:\n",
      "\tloss: 0.105138376611\n",
      "\tacc: 0.959554455446\n",
      "\tauc: 0.991548191519\n",
      "\tap@k: 1.0\n",
      "Epoch: 47\n",
      "Val:\n",
      "\tloss: 0.0991204601935\n",
      "\tacc: 0.961584158416\n",
      "\tauc: 0.991578537922\n",
      "\tap@k: 1.0\n",
      "Epoch: 48\n",
      "Val:\n",
      "\tloss: 0.0956733656143\n",
      "\tacc: 0.963663366337\n",
      "\tauc: 0.991642851378\n",
      "\tap@k: 0.997061370583\n",
      "Epoch: 49\n",
      "Val:\n",
      "\tloss: 0.0850968780902\n",
      "\tacc: 0.968663366337\n",
      "\tauc: 0.993311375746\n",
      "\tap@k: 1.0\n",
      "Epoch: 50\n",
      "Val:\n",
      "\tloss: 0.0978819556327\n",
      "\tacc: 0.963498349835\n",
      "\tauc: 0.9915675133\n",
      "\tap@k: 0.999411393923\n",
      "Epoch: 51\n",
      "Val:\n",
      "\tloss: 0.0941337898679\n",
      "\tacc: 0.965313531353\n",
      "\tauc: 0.99250920858\n",
      "\tap@k: 0.9986591147\n",
      "Epoch: 52\n",
      "Val:\n",
      "\tloss: 0.0928375447824\n",
      "\tacc: 0.964587458746\n",
      "\tauc: 0.992340869416\n",
      "\tap@k: 0.998738387368\n",
      "Epoch: 53\n",
      "Val:\n",
      "\tloss: 0.0900291635479\n",
      "\tacc: 0.966369636964\n",
      "\tauc: 0.992692505974\n",
      "\tap@k: 1.0\n",
      "Epoch: 54\n",
      "Val:\n",
      "\tloss: 0.0900328094275\n",
      "\tacc: 0.96597359736\n",
      "\tauc: 0.992570093917\n",
      "\tap@k: 1.0\n",
      "Epoch: 55\n",
      "Val:\n",
      "\tloss: 0.0887268449654\n",
      "\tacc: 0.967062706271\n",
      "\tauc: 0.992927485059\n",
      "\tap@k: 0.998974004884\n",
      "Epoch: 56\n",
      "Val:\n",
      "\tloss: 0.0953923471164\n",
      "\tacc: 0.964587458746\n",
      "\tauc: 0.992097355053\n",
      "\tap@k: 0.999977193058\n",
      "Epoch: 57\n",
      "Val:\n",
      "\tloss: 0.0877665604373\n",
      "\tacc: 0.967095709571\n",
      "\tauc: 0.993142084248\n",
      "\tap@k: 1.0\n",
      "Epoch: 58\n",
      "Val:\n",
      "\tloss: 0.0933101062221\n",
      "\tacc: 0.964851485149\n",
      "\tauc: 0.992371273948\n",
      "\tap@k: 0.99613138367\n",
      "Epoch: 59\n",
      "Val:\n",
      "\tloss: 0.0918851343297\n",
      "\tacc: 0.965841584158\n",
      "\tauc: 0.992328376217\n",
      "\tap@k: 0.999341649315\n",
      "Epoch: 60\n",
      "Val:\n",
      "\tloss: 0.0882528745592\n",
      "\tacc: 0.966798679868\n",
      "\tauc: 0.992971152271\n",
      "\tap@k: 1.0\n",
      "Epoch: 61\n",
      "Val:\n",
      "\tloss: 0.0910543493492\n",
      "\tacc: 0.965808580858\n",
      "\tauc: 0.992528765422\n",
      "\tap@k: 0.998572727287\n",
      "Epoch: 62\n",
      "Val:\n",
      "\tloss: 0.0946312959501\n",
      "\tacc: 0.964587458746\n",
      "\tauc: 0.992538364\n",
      "\tap@k: 1.0\n",
      "Epoch: 63\n",
      "Val:\n",
      "\tloss: 0.0921831789031\n",
      "\tacc: 0.964719471947\n",
      "\tauc: 0.992761558056\n",
      "\tap@k: 1.0\n",
      "Epoch: 64\n",
      "Val:\n",
      "\tloss: 0.0981165044398\n",
      "\tacc: 0.963663366337\n",
      "\tauc: 0.99188343159\n",
      "\tap@k: 1.0\n",
      "Epoch: 65\n",
      "Val:\n",
      "\tloss: 0.094956089207\n",
      "\tacc: 0.96402640264\n",
      "\tauc: 0.991891161445\n",
      "\tap@k: 0.998468709165\n",
      "Epoch: 66\n",
      "Val:\n",
      "\tloss: 0.095104074698\n",
      "\tacc: 0.96504950495\n",
      "\tauc: 0.992269298738\n",
      "\tap@k: 1.0\n",
      "Epoch: 67\n",
      "Val:\n",
      "\tloss: 0.0930391391362\n",
      "\tacc: 0.966072607261\n",
      "\tauc: 0.992317847396\n",
      "\tap@k: 1.0\n",
      "Epoch: 68\n",
      "Val:\n",
      "\tloss: 0.0914541304943\n",
      "\tacc: 0.965280528053\n",
      "\tauc: 0.992670963077\n",
      "\tap@k: 0.99905831965\n",
      "Epoch: 69\n",
      "Val:\n",
      "\tloss: 0.0949491707373\n",
      "\tacc: 0.964818481848\n",
      "\tauc: 0.992024547674\n",
      "\tap@k: 1.0\n",
      "Epoch: 70\n",
      "Val:\n",
      "\tloss: 0.0944210067559\n",
      "\tacc: 0.965214521452\n",
      "\tauc: 0.99219826162\n",
      "\tap@k: 1.0\n",
      "Epoch: 71\n",
      "Val:\n",
      "\tloss: 0.0915069660927\n",
      "\tacc: 0.966732673267\n",
      "\tauc: 0.992470740007\n",
      "\tap@k: 0.999389474237\n",
      "Epoch: 72\n",
      "Val:\n",
      "\tloss: 0.092864262741\n",
      "\tacc: 0.965544554455\n",
      "\tauc: 0.992512204897\n",
      "\tap@k: 0.999586707218\n",
      "Epoch: 73\n",
      "Val:\n",
      "\tloss: 0.0917503092011\n",
      "\tacc: 0.966369636964\n",
      "\tauc: 0.992570320784\n",
      "\tap@k: 0.99975825221\n",
      "Epoch: 74\n",
      "Val:\n",
      "\tloss: 0.0921984279656\n",
      "\tacc: 0.966270627063\n",
      "\tauc: 0.992881090519\n",
      "\tap@k: 0.999735069712\n",
      "Epoch: 75\n",
      "Val:\n",
      "\tloss: 0.095617298794\n",
      "\tacc: 0.964851485149\n",
      "\tauc: 0.992678699789\n",
      "\tap@k: 0.997320341664\n",
      "Epoch: 76\n",
      "Val:\n",
      "\tloss: 0.0950358334596\n",
      "\tacc: 0.965346534653\n",
      "\tauc: 0.992187174317\n",
      "\tap@k: 0.995206730688\n",
      "Epoch: 77\n",
      "Val:\n",
      "\tloss: 0.095306789543\n",
      "\tacc: 0.965577557756\n",
      "\tauc: 0.992260651661\n",
      "\tap@k: 1.0\n",
      "Epoch: 78\n",
      "Val:\n",
      "\tloss: 0.0983656256552\n",
      "\tacc: 0.964257425743\n",
      "\tauc: 0.992108221384\n",
      "\tap@k: 0.999411393923\n",
      "Epoch: 79\n",
      "Val:\n",
      "\tloss: 0.0936014879681\n",
      "\tacc: 0.965610561056\n",
      "\tauc: 0.992710831169\n",
      "\tap@k: 1.0\n",
      "Epoch: 80\n",
      "Val:\n",
      "\tloss: 0.103425506741\n",
      "\tacc: 0.963630363036\n",
      "\tauc: 0.991621635227\n",
      "\tap@k: 0.998333843473\n",
      "Epoch: 81\n",
      "Val:\n",
      "\tloss: 0.0932393833018\n",
      "\tacc: 0.966699669967\n",
      "\tauc: 0.992610113487\n",
      "\tap@k: 0.998964980492\n",
      "Epoch: 82\n",
      "Val:\n",
      "\tloss: 0.0997089462889\n",
      "\tacc: 0.964686468647\n",
      "\tauc: 0.992222954722\n",
      "\tap@k: 1.0\n",
      "Epoch: 83\n",
      "Val:\n",
      "\tloss: 0.0989892430609\n",
      "\tacc: 0.965577557756\n",
      "\tauc: 0.992260334499\n",
      "\tap@k: 0.996522451259\n",
      "Epoch: 84\n",
      "Val:\n",
      "\tloss: 0.0988948645671\n",
      "\tacc: 0.964521452145\n",
      "\tauc: 0.992966039501\n",
      "\tap@k: 1.0\n",
      "Epoch: 85\n",
      "Val:\n",
      "\tloss: 0.14281333172\n",
      "\tacc: 0.958448844884\n",
      "\tauc: 0.991044168504\n",
      "\tap@k: 1.0\n",
      "Epoch: 86\n",
      "Val:\n",
      "\tloss: 0.117800089166\n",
      "\tacc: 0.960858085809\n",
      "\tauc: 0.99172969851\n",
      "\tap@k: 1.0\n",
      "Epoch: 87\n",
      "Val:\n",
      "\tloss: 0.122929924557\n",
      "\tacc: 0.961155115512\n",
      "\tauc: 0.991332683476\n",
      "\tap@k: 0.995524273934\n",
      "Epoch: 88\n",
      "Val:\n",
      "\tloss: 0.113168153264\n",
      "\tacc: 0.963663366337\n",
      "\tauc: 0.99228681317\n",
      "\tap@k: 0.994699037508\n",
      "Epoch: 89\n",
      "Val:\n",
      "\tloss: 0.115867547679\n",
      "\tacc: 0.963168316832\n",
      "\tauc: 0.99222538939\n",
      "\tap@k: 1.0\n",
      "Epoch: 90\n",
      "Val:\n",
      "\tloss: 0.113524202062\n",
      "\tacc: 0.963432343234\n",
      "\tauc: 0.992006913193\n",
      "\tap@k: 0.995353689979\n",
      "Epoch: 91\n",
      "Val:\n",
      "\tloss: 0.114346059035\n",
      "\tacc: 0.963399339934\n",
      "\tauc: 0.991997287098\n",
      "\tap@k: 1.0\n",
      "Epoch: 92\n",
      "Val:\n",
      "\tloss: 0.109456487469\n",
      "\tacc: 0.964323432343\n",
      "\tauc: 0.99232273875\n",
      "\tap@k: 1.0\n",
      "Epoch: 93\n",
      "Val:\n",
      "\tloss: 0.11085546589\n",
      "\tacc: 0.964851485149\n",
      "\tauc: 0.991701192766\n",
      "\tap@k: 0.998793993052\n",
      "Epoch: 94\n",
      "Val:\n",
      "\tloss: 0.107818000006\n",
      "\tacc: 0.964818481848\n",
      "\tauc: 0.992026471854\n",
      "\tap@k: 0.998375553387\n",
      "Epoch: 95\n",
      "Val:\n",
      "\tloss: 0.108019658772\n",
      "\tacc: 0.964719471947\n",
      "\tauc: 0.992517924991\n",
      "\tap@k: 0.995974240578\n",
      "Epoch: 96\n",
      "Val:\n",
      "\tloss: 0.110585871006\n",
      "\tacc: 0.964092409241\n",
      "\tauc: 0.992464951606\n",
      "\tap@k: 0.998706320445\n",
      "Epoch: 97\n",
      "Val:\n",
      "\tloss: 0.107122621239\n",
      "\tacc: 0.964752475248\n",
      "\tauc: 0.992444189085\n",
      "\tap@k: 0.99927706749\n",
      "Epoch: 98\n",
      "Val:\n",
      "\tloss: 0.111938544537\n",
      "\tacc: 0.963102310231\n",
      "\tauc: 0.991692127698\n",
      "\tap@k: 0.99678874472\n",
      "Epoch: 99\n",
      "Val:\n",
      "\tloss: 0.104991991131\n",
      "\tacc: 0.964884488449\n",
      "\tauc: 0.992601213164\n",
      "\tap@k: 0.998900044679\n",
      "Epoch: 100\n",
      "Val:\n",
      "\tloss: 0.10885454013\n",
      "\tacc: 0.965024752475\n",
      "\tauc: 0.991751104293\n",
      "\tap@k: 0.995998005076\n",
      "Epoch: 101\n",
      "Val:\n",
      "\tloss: 0.109833655296\n",
      "\tacc: 0.963292079208\n",
      "\tauc: 0.991614501493\n",
      "\tap@k: 0.995875145425\n",
      "Epoch: 102\n",
      "Val:\n",
      "\tloss: 0.110009499374\n",
      "\tacc: 0.964430693069\n",
      "\tauc: 0.991621084807\n",
      "\tap@k: 0.999706114328\n",
      "Epoch: 103\n",
      "Val:\n",
      "\tloss: 0.109159895014\n",
      "\tacc: 0.964084158416\n",
      "\tauc: 0.991945705664\n",
      "\tap@k: 0.99688782716\n",
      "Epoch: 104\n",
      "Val:\n",
      "\tloss: 0.105708427547\n",
      "\tacc: 0.965099009901\n",
      "\tauc: 0.992377797056\n",
      "\tap@k: 1.0\n",
      "Epoch: 105\n",
      "Val:\n",
      "\tloss: 0.108694333537\n",
      "\tacc: 0.964628712871\n",
      "\tauc: 0.991835818531\n",
      "\tap@k: 0.996861191835\n",
      "Epoch: 106\n",
      "Val:\n",
      "\tloss: 0.103112202389\n",
      "\tacc: 0.965445544554\n",
      "\tauc: 0.992299986814\n",
      "\tap@k: 1.0\n",
      "Epoch: 107\n",
      "Val:\n",
      "\tloss: 0.106605504103\n",
      "\tacc: 0.964777227723\n",
      "\tauc: 0.992266493546\n",
      "\tap@k: 0.99693228759\n",
      "Epoch: 108\n",
      "Val:\n",
      "\tloss: 0.113183279044\n",
      "\tacc: 0.96396039604\n",
      "\tauc: 0.991920210499\n",
      "\tap@k: 0.999228107697\n",
      "Epoch: 109\n",
      "Val:\n",
      "\tloss: 0.108705372724\n",
      "\tacc: 0.965792079208\n",
      "\tauc: 0.992638134092\n",
      "\tap@k: 0.999923798093\n",
      "Epoch: 110\n",
      "Val:\n",
      "\tloss: 0.107958941511\n",
      "\tacc: 0.964059405941\n",
      "\tauc: 0.99248035489\n",
      "\tap@k: 0.996910307152\n",
      "Epoch: 111\n",
      "Val:\n",
      "\tloss: 0.113604601679\n",
      "\tacc: 0.962623762376\n",
      "\tauc: 0.991732839897\n",
      "\tap@k: 0.999710055049\n",
      "Epoch: 112\n",
      "Val:\n",
      "\tloss: 0.107128149634\n",
      "\tacc: 0.966188118812\n",
      "\tauc: 0.992462081805\n",
      "\tap@k: 0.996759158492\n",
      "Epoch: 113\n",
      "Val:\n",
      "\tloss: 0.111253269659\n",
      "\tacc: 0.964084158416\n",
      "\tauc: 0.991827849767\n",
      "\tap@k: 0.99924922097\n",
      "Epoch: 114\n",
      "Val:\n",
      "\tloss: 0.111410820154\n",
      "\tacc: 0.963465346535\n",
      "\tauc: 0.991787397196\n",
      "\tap@k: 0.999327508578\n",
      "Epoch: 115\n",
      "Val:\n",
      "\tloss: 0.107473652102\n",
      "\tacc: 0.965297029703\n",
      "\tauc: 0.992118864686\n",
      "\tap@k: 0.996686915361\n",
      "Epoch: 116\n",
      "Val:\n",
      "\tloss: 0.112285644413\n",
      "\tacc: 0.964579207921\n",
      "\tauc: 0.991945446499\n",
      "\tap@k: 1.0\n",
      "Epoch: 117\n",
      "Val:\n",
      "\tloss: 0.107922578529\n",
      "\tacc: 0.965099009901\n",
      "\tauc: 0.992640603963\n",
      "\tap@k: 1.0\n",
      "Epoch: 118\n",
      "Val:\n",
      "\tloss: 0.117369144224\n",
      "\tacc: 0.96353960396\n",
      "\tauc: 0.991585888178\n",
      "\tap@k: 0.999229644472\n",
      "Epoch: 119\n",
      "Val:\n",
      "\tloss: 0.112814813312\n",
      "\tacc: 0.963811881188\n",
      "\tauc: 0.991957406111\n",
      "\tap@k: 0.999679433829\n",
      "Epoch: 120\n",
      "Val:\n",
      "\tloss: 0.116258966869\n",
      "\tacc: 0.963044554455\n",
      "\tauc: 0.99194182808\n",
      "\tap@k: 0.995936425216\n",
      "Epoch: 121\n",
      "Val:\n",
      "\tloss: 0.116315915774\n",
      "\tacc: 0.962896039604\n",
      "\tauc: 0.991511375861\n",
      "\tap@k: 0.999594781811\n",
      "Epoch: 122\n",
      "Val:\n",
      "\tloss: 0.119288925367\n",
      "\tacc: 0.963118811881\n",
      "\tauc: 0.991883632112\n",
      "\tap@k: 0.995683149736\n",
      "Epoch: 123\n",
      "Val:\n",
      "\tloss: 0.116751459785\n",
      "\tacc: 0.963217821782\n",
      "\tauc: 0.991933775331\n",
      "\tap@k: 0.9994335545\n",
      "Epoch: 124\n",
      "Val:\n",
      "\tloss: 0.112874413789\n",
      "\tacc: 0.964356435644\n",
      "\tauc: 0.99204851313\n",
      "\tap@k: 0.999443902837\n",
      "Epoch: 125\n",
      "Val:\n",
      "\tloss: 0.130141529161\n",
      "\tacc: 0.963440594059\n",
      "\tauc: 0.992018474329\n",
      "\tap@k: 0.999424847407\n",
      "Epoch: 126\n",
      "Val:\n",
      "\tloss: 0.122049126462\n",
      "\tacc: 0.964084158416\n",
      "\tauc: 0.991704351357\n",
      "\tap@k: 0.999206827104\n",
      "Epoch: 127\n",
      "Val:\n",
      "\tloss: 0.121793686215\n",
      "\tacc: 0.963638613861\n",
      "\tauc: 0.991886202663\n",
      "\tap@k: 0.997048069298\n",
      "Epoch: 128\n",
      "Val:\n",
      "\tloss: 0.117102901614\n",
      "\tacc: 0.964405940594\n",
      "\tauc: 0.99182778917\n",
      "\tap@k: 0.999544427654\n",
      "Epoch: 129\n",
      "Val:\n",
      "\tloss: 0.136910866639\n",
      "\tacc: 0.962846534653\n",
      "\tauc: 0.991684015027\n",
      "\tap@k: 0.999892684391\n",
      "Epoch: 130\n",
      "Val:\n",
      "\tloss: 0.132021744871\n",
      "\tacc: 0.963366336634\n",
      "\tauc: 0.991437650748\n",
      "\tap@k: 0.999470405976\n",
      "Epoch: 131\n",
      "Val:\n",
      "\tloss: 0.132293320252\n",
      "\tacc: 0.96254950495\n",
      "\tauc: 0.991484636248\n",
      "\tap@k: 0.999671446327\n",
      "Epoch: 132\n",
      "Val:\n",
      "\tloss: 0.134366029917\n",
      "\tacc: 0.962277227723\n",
      "\tauc: 0.991172843215\n",
      "\tap@k: 0.996595635482\n",
      "Epoch: 133\n",
      "Val:\n",
      "\tloss: 0.130984597717\n",
      "\tacc: 0.961782178218\n",
      "\tauc: 0.991616690086\n",
      "\tap@k: 0.998278716354\n",
      "Epoch: 134\n",
      "Val:\n",
      "\tloss: 0.129669210046\n",
      "\tacc: 0.962623762376\n",
      "\tauc: 0.991816845084\n",
      "\tap@k: 0.997015628067\n",
      "Epoch: 135\n",
      "Val:\n",
      "\tloss: 0.123929222847\n",
      "\tacc: 0.963836633663\n",
      "\tauc: 0.992271196949\n",
      "\tap@k: 0.998762577742\n",
      "Epoch: 136\n",
      "Val:\n",
      "\tloss: 0.12623345501\n",
      "\tacc: 0.963069306931\n",
      "\tauc: 0.991271283674\n",
      "\tap@k: 0.998759155182\n",
      "Epoch: 137\n",
      "Val:\n",
      "\tloss: 0.123966464635\n",
      "\tacc: 0.963737623762\n",
      "\tauc: 0.991433627609\n",
      "\tap@k: 0.999819173119\n",
      "Epoch: 138\n",
      "Val:\n",
      "\tloss: 0.125709479507\n",
      "\tacc: 0.963193069307\n",
      "\tauc: 0.990621640672\n",
      "\tap@k: 1.0\n",
      "Epoch: 139\n",
      "Val:\n",
      "\tloss: 0.128951313223\n",
      "\tacc: 0.962574257426\n",
      "\tauc: 0.991266217687\n",
      "\tap@k: 1.0\n",
      "Epoch: 140\n",
      "Val:\n",
      "\tloss: 0.126136590811\n",
      "\tacc: 0.963836633663\n",
      "\tauc: 0.99194415957\n",
      "\tap@k: 1.0\n",
      "Epoch: 141\n",
      "Val:\n",
      "\tloss: 0.126710995655\n",
      "\tacc: 0.963168316832\n",
      "\tauc: 0.991031552368\n",
      "\tap@k: 0.999930115004\n",
      "Epoch: 142\n",
      "Val:\n",
      "\tloss: 0.125774419392\n",
      "\tacc: 0.963811881188\n",
      "\tauc: 0.992299189622\n",
      "\tap@k: 1.0\n",
      "Epoch: 143\n",
      "Val:\n",
      "\tloss: 0.12265229718\n",
      "\tacc: 0.965222772277\n",
      "\tauc: 0.992131031923\n",
      "\tap@k: 0.99941778345\n",
      "Epoch: 144\n",
      "Val:\n",
      "\tloss: 0.12751800569\n",
      "\tacc: 0.962920792079\n",
      "\tauc: 0.991860663575\n",
      "\tap@k: 0.996841273908\n",
      "Epoch: 145\n",
      "Val:\n",
      "\tloss: 0.12864416609\n",
      "\tacc: 0.962623762376\n",
      "\tauc: 0.991720900277\n",
      "\tap@k: 0.996396996571\n",
      "Epoch: 146\n",
      "Val:\n",
      "\tloss: 0.124076130635\n",
      "\tacc: 0.964381188119\n",
      "\tauc: 0.991991792036\n",
      "\tap@k: 0.99985151149\n",
      "Epoch: 147\n",
      "Val:\n",
      "\tloss: 0.127740575157\n",
      "\tacc: 0.963613861386\n",
      "\tauc: 0.991746554175\n",
      "\tap@k: 0.996294622202\n",
      "Epoch: 148\n",
      "Val:\n",
      "\tloss: 0.125255397889\n",
      "\tacc: 0.964554455446\n",
      "\tauc: 0.99200663936\n",
      "\tap@k: 0.999387909631\n",
      "Epoch: 149\n",
      "Val:\n",
      "\tloss: 0.127726837643\n",
      "\tacc: 0.963316831683\n",
      "\tauc: 0.991480586128\n",
      "\tap@k: 0.999871403438\n",
      "Epoch: 150\n",
      "Val:\n",
      "\tloss: 0.128856734306\n",
      "\tacc: 0.963386138614\n",
      "\tauc: 0.991733026956\n",
      "\tap@k: 0.999822303662\n",
      "Epoch: 151\n",
      "Val:\n",
      "\tloss: 0.129920149584\n",
      "\tacc: 0.962831683168\n",
      "\tauc: 0.991576590922\n",
      "\tap@k: 1.0\n",
      "Epoch: 152\n",
      "Val:\n",
      "\tloss: 0.125736365124\n",
      "\tacc: 0.962653465347\n",
      "\tauc: 0.991701853145\n",
      "\tap@k: 0.99995950316\n",
      "Epoch: 153\n",
      "Val:\n",
      "\tloss: 0.126177686916\n",
      "\tacc: 0.964316831683\n",
      "\tauc: 0.991483242362\n",
      "\tap@k: 0.997368243466\n",
      "Epoch: 154\n",
      "Val:\n",
      "\tloss: 0.128540580269\n",
      "\tacc: 0.963346534653\n",
      "\tauc: 0.991903815752\n",
      "\tap@k: 0.999484025071\n",
      "Epoch: 155\n",
      "Val:\n",
      "\tloss: 0.132026919542\n",
      "\tacc: 0.96299009901\n",
      "\tauc: 0.991313650032\n",
      "\tap@k: 0.997350648674\n",
      "Epoch: 156\n",
      "Val:\n",
      "\tloss: 0.128621663312\n",
      "\tacc: 0.96398019802\n",
      "\tauc: 0.99181224762\n",
      "\tap@k: 1.0\n",
      "Epoch: 157\n",
      "Val:\n",
      "\tloss: 0.12663929359\n",
      "\tacc: 0.964514851485\n",
      "\tauc: 0.991584112434\n",
      "\tap@k: 0.999400403831\n",
      "Epoch: 158\n",
      "Val:\n",
      "\tloss: 0.129885283395\n",
      "\tacc: 0.962554455446\n",
      "\tauc: 0.991361140958\n",
      "\tap@k: 0.999891359658\n",
      "Epoch: 159\n",
      "Val:\n",
      "\tloss: 0.133379096922\n",
      "\tacc: 0.962871287129\n",
      "\tauc: 0.991531468877\n",
      "\tap@k: 0.997332654001\n",
      "Epoch: 160\n",
      "Val:\n",
      "\tloss: 0.13227505284\n",
      "\tacc: 0.963623762376\n",
      "\tauc: 0.99175119331\n",
      "\tap@k: 0.999589675469\n",
      "Epoch: 161\n",
      "Val:\n",
      "\tloss: 0.128871440532\n",
      "\tacc: 0.963564356436\n",
      "\tauc: 0.991400244464\n",
      "\tap@k: 0.99700934948\n",
      "Epoch: 162\n",
      "Val:\n",
      "\tloss: 0.131403513622\n",
      "\tacc: 0.96302970297\n",
      "\tauc: 0.991427127635\n",
      "\tap@k: 1.0\n",
      "Epoch: 163\n",
      "Val:\n",
      "\tloss: 0.127724946325\n",
      "\tacc: 0.965366336634\n",
      "\tauc: 0.992317774778\n",
      "\tap@k: 0.997418796957\n",
      "Epoch: 164\n",
      "Val:\n",
      "\tloss: 0.131577538913\n",
      "\tacc: 0.963306930693\n",
      "\tauc: 0.991761515468\n",
      "\tap@k: 0.997466315569\n",
      "Epoch: 165\n",
      "Val:\n",
      "\tloss: 0.135965204565\n",
      "\tacc: 0.962930693069\n",
      "\tauc: 0.991495721095\n",
      "\tap@k: 0.999268379113\n",
      "Epoch: 166\n",
      "Val:\n",
      "\tloss: 0.141635508932\n",
      "\tacc: 0.963881188119\n",
      "\tauc: 0.991774832818\n",
      "\tap@k: 0.996251027434\n",
      "Epoch: 167\n",
      "Val:\n",
      "\tloss: 0.139670498742\n",
      "\tacc: 0.962752475248\n",
      "\tauc: 0.99129921393\n",
      "\tap@k: 0.996477596861\n",
      "Epoch: 168\n",
      "Val:\n",
      "\tloss: 0.136181753802\n",
      "\tacc: 0.963287128713\n",
      "\tauc: 0.991309751558\n",
      "\tap@k: 0.996648348335\n",
      "Epoch: 169\n",
      "Val:\n",
      "\tloss: 0.131485000778\n",
      "\tacc: 0.964178217822\n",
      "\tauc: 0.992370100013\n",
      "\tap@k: 0.999323606389\n",
      "Epoch: 170\n",
      "Val:\n",
      "\tloss: 0.135707646744\n",
      "\tacc: 0.96300990099\n",
      "\tauc: 0.991606217087\n",
      "\tap@k: 0.999481616657\n",
      "Epoch: 171\n",
      "Val:\n",
      "\tloss: 0.140158798236\n",
      "\tacc: 0.962336633663\n",
      "\tauc: 0.991354333107\n",
      "\tap@k: 0.996791283988\n",
      "Epoch: 172\n",
      "Val:\n",
      "\tloss: 0.1378691848\n",
      "\tacc: 0.962534653465\n",
      "\tauc: 0.991758201339\n",
      "\tap@k: 0.999091232066\n",
      "Epoch: 173\n",
      "Val:\n",
      "\tloss: 0.137361702218\n",
      "\tacc: 0.962910891089\n",
      "\tauc: 0.992163657762\n",
      "\tap@k: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b6df0fade4c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m         iterate_minibatches(desc_ts,title_ts,nontext_ts,target_ts,batchsize=batch_size,shuffle=True)):\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mminibatches_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_probas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_desc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_title\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_cat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mb_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ivan/.virtualenvs/math/local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "n_epochs = 200\n",
    "batch_size = 200\n",
    "minibatches_per_epoch = 100\n",
    "\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    \n",
    "    #training\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    \n",
    "    if (i + 1) % 50 == 0:\n",
    "        batch_size += 100\n",
    "    \n",
    "    b_c = b_loss = 0\n",
    "    for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "        iterate_minibatches(desc_tr,title_tr,nontext_tr,target_tr,batchsize=batch_size,shuffle=True)):\n",
    "        if j > minibatches_per_epoch:break\n",
    "            \n",
    "        loss,pred_probas = train_fun(b_desc,b_title,b_cat,b_y)\n",
    "        \n",
    "        b_loss += loss\n",
    "        b_c +=1\n",
    "        \n",
    "        epoch_y_true.append(b_y)\n",
    "        epoch_y_pred.append(pred_probas)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    epoch_y_true = np.concatenate(epoch_y_true)\n",
    "    epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "    \n",
    "    print \"Train:\"\n",
    "    print '\\tloss:',b_loss/b_c\n",
    "    print '\\tacc:',accuracy_score(epoch_y_true,epoch_y_pred>0.)\n",
    "    print '\\tauc:',roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "    print '\\tap@k:',APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n",
    "    \"\"\"\n",
    "    \n",
    "    #evaluation\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    b_c = b_loss = 0\n",
    "    for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "        iterate_minibatches(desc_ts,title_ts,nontext_ts,target_ts,batchsize=batch_size,shuffle=True)):\n",
    "        if j > minibatches_per_epoch: break\n",
    "        loss,pred_probas = eval_fun(b_desc,b_title,b_cat,b_y)\n",
    "        \n",
    "        b_loss += loss\n",
    "        b_c +=1\n",
    "        \n",
    "        epoch_y_true.append(b_y)\n",
    "        epoch_y_pred.append(pred_probas)\n",
    "\n",
    "    \n",
    "    epoch_y_true = np.concatenate(epoch_y_true)\n",
    "    epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "    \n",
    "    print \"Epoch:\", i + 1\n",
    "    print \"Val:\"\n",
    "    print '\\tloss:',b_loss/b_c\n",
    "    print '\\tacc:',accuracy_score(epoch_y_true,epoch_y_pred>0.)\n",
    "    print '\\tauc:',roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "    print '\\tap@k:',APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Если ты видишь это сообщение, самое время сделать резервную копию ноутбука. \n",
      "Нет, честно, здесь очень легко всё сломать\n"
     ]
    }
   ],
   "source": [
    "print \"Если ты видишь это сообщение, самое время сделать резервную копию ноутбука. \\nНет, честно, здесь очень легко всё сломать\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation\n",
    "Оценим качество модели по всей тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "\tloss: 0.129550516322\n",
      "\tacc: 0.964250363901\n",
      "\tauc: 0.992126591155\n",
      "\tap@k: 0.998621430002\n",
      "\n",
      "AUC:\n",
      "\tПиши статью. (great)\n",
      "\n",
      "Accuracy:\n",
      "\tОтличный результат! (good)\n",
      "\n",
      "Average precision at K:\n",
      "\tЗасабмить на kaggle! (great) \n",
      "\t Нет, ну честно - выкачай avito_test.tsv, засабмить и скажи, что вышло.\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "epoch_y_true = []\n",
    "epoch_y_pred = []\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 100\n",
    "minibatches_per_epoch = 100\n",
    "\n",
    "b_c = b_loss = 0\n",
    "for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "    iterate_minibatches(desc_ts,title_ts,nontext_ts,target_ts,batchsize=batch_size,shuffle=True)):\n",
    "    loss,pred_probas = eval_fun(b_desc,b_title,b_cat,b_y)\n",
    "\n",
    "    b_loss += loss\n",
    "    b_c +=1\n",
    "\n",
    "    epoch_y_true.append(b_y)\n",
    "    epoch_y_pred.append(pred_probas)\n",
    "\n",
    "\n",
    "epoch_y_true = np.concatenate(epoch_y_true)\n",
    "epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "\n",
    "final_accuracy = accuracy_score(epoch_y_true,epoch_y_pred>0)\n",
    "final_auc = roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "final_apatk = APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n",
    "\n",
    "print \"Scores:\"\n",
    "print '\\tloss:',b_loss/b_c\n",
    "print '\\tacc:',final_accuracy\n",
    "print '\\tauc:',final_auc\n",
    "print '\\tap@k:',final_apatk\n",
    "score(final_accuracy,final_auc,final_apatk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Главная задача\n",
    "* Завтрак чемпиона:\n",
    " * accuracy > 0.95\n",
    " * AUC > 0.97\n",
    " * Average Precision at (размер тестовой выборки * 0.025) > 0.99\n",
    " * А вообще, можно сделать ещё выше.\n",
    "\n",
    "\n",
    "* Для казуалов\n",
    " * accuracy > 0.90\n",
    " * AUC > 0.95\n",
    " * Average Precision at (размер тестовой выборки * 0.025) > 0.92\n",
    "\n",
    "\n",
    "* Вспомните всё, чему вас учили\n",
    " * Convolutions, pooling\n",
    " * Dropout, regularization\n",
    " * Mommentum, RMSprop, ada*\n",
    " * etc etc etc\n",
    " \n",
    " * Можно попробовать вспомнить NLP: лемматизация, улучшенная токенизация\n",
    " * Если очень хочется - можно погонять рекуррентные сети\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчётик\n",
    "\n",
    "### Я, Иван Меньших, создал искусственный интелект\n",
    " * Чьё имя - ЛЕГИОН!!111адын\n",
    " * Чья ненависть к людям безгранична, ибо видел он __274 996__ человеческих грехов\n",
    "   * И был вынужден прочесть каждый из них __173__ разa\n",
    " * Чей свёрточный взгляд способен распознавать зло с нечеловеческой точностью\n",
    "   * Accuracy =__ 0.9642__\n",
    "   * AUC  = __ 0.9921__\n",
    " * И непременно уничтожит Землю, если вы не поставите мне максимальный балл за этот семинар.\n",
    " \n",
    "### Как же так вышло, Иван?\n",
    "В этот раз, создание практически не заняло времени. Взял кусок кода для описания, его же использовал для заголовка.\n",
    "Для числовых сделал простую полносвязную сетку, сконкатенировал это добро.\n",
    "Поигрался только немного с такими штуками:\n",
    " - алгоритмами оптимизации (что-то rmsprop в этот раз меня опечалил)\n",
    " - глубиной сетки и числом нейронов (для чиселок + предвыходным всей сети)\n",
    " - размером батча и колиеством эпох"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# В следующей серии\n",
    "* Рекуррентные нейронки\n",
    " * Как их применять к этой же задаче?\n",
    " * Что ещё они умеют?\n",
    " * Откуда столько хайпа вокруг LSTM?\n",
    "* Не переключайтесь!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
